@article{swarm_survey,
  title={Swarm robotics: A review from the swarm engineering perspective},
  author={Brambilla, Manuele and Ferrante, Eliseo and Birattari, Mauro and Dorigo, Marco},
  journal={Swarm Intelligence},
  volume={7},
  number={1},
  pages={1--41},
  year={2013},
  publisher={Springer}
}
@misc{noauthor_lighthouse_nodate,
	title = {Lighthouse positioning methods {\textbar} {Bitcraze}},
	url = {https://www.bitcraze.io/documentation/repository/crazyflie-firmware/master/functional-areas/lighthouse/positioning_methods/},
	urldate = {2024-10-15},
	file = {Lighthouse positioning methods | Bitcraze:files/364/positioning_methods.html:text/html},
}

@article{carstens_intelligent_nodate,
	title = {Intelligent {Systems} for {Next} {Generation} {Drone} {Functionality}},
	language = {en},
	author = {Carstens, Thomas},
	file = {Carstens - Intelligent Systems for Next Generation Drone Func.pdf:files/361/Carstens - Intelligent Systems for Next Generation Drone Func.pdf:application/pdf},
}
@misc{max,
  author = {Maximilien Menesguen},
  title = {Maximilien Menesguen},
  year = {2023},
  howpublished = {\url{https://ift.devinci.fr/member/maximilien-menesguen}},
  note = {Accessed: 2024-10-10}
}
@article{human_drone_interaction,
  title={A review of human-drone interaction: Methods and applications},
  author={Shahbazi, Maziar and Rajabzadeh, Iman and Nourbakhsh, Saeid and Saad, Wasif and Mohammadi, Mojtaba},
  journal={Computers \& Human Behavior},
  volume={106},
  pages={106270},
  year={2020},
  publisher={Elsevier}
}

@misc{bitcraze_cflib,
  author = {Bitcraze},
  title = {CFLib - Python library for Crazyflie},
  year = {2020},
  howpublished = {\url{https://www.bitcraze.io/documentation/repository/crazyflie-lib-python/master/}},
  note = {Accessed: 2024-10-10}
}
@inproceedings{preiss2017crazyswarm,
  title={Crazyswarm: A large nano-quadcopter swarm},
  author={Preiss, James A. and Honig, Wolfgang and Sukhatme, Gaurav S. and Ayanian, Nora},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={3299-3304},
  year={2017},
  organization={IEEE}
}
@article{asyncio,
  title={asyncio: Asynchronous I/O, event loop, coroutines and tasks},
  author={Python Software Foundation},
  year={2022},
  url={https://docs.python.org/3/library/asyncio.html},
  note={Accessed: 2024-10-10}
}
@article{drone_me,
  title={Drone \& Me: An Exploration Into Natural Human-Drone Interaction},
  author={Cauchard, Jessica R. and et al.},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  year={2015}
}

@inproceedings{ju_safety,
  title={Safe human-drone interaction in indoor environments},
  author={Ju, X. and others},
  booktitle={International Conference on Human-Robot Interaction},
  year={2017}
}

@article{crazyflie,
  title={CrazySwarm: A large nano-quadcopter swarm},
  author={Preiss, J. A. and others},
  journal={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2017}
}

@article{kilobot,
  title={Kilobot: A low-cost scalable robot system for collective behaviors},
  author={Rubenstein, M. and others},
  journal={2012 IEEE International Conference on Robotics and Automation},
  year={2012}
}

@inproceedings{crazychoir,
  title={CrazyChoir: Artistic performance with multiple Crazyflie drones},
  author={Sanchez-Lopez, J. L. and others},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2022}
}

@inproceedings{flyjacket,
  title={FlyJacket: An upper body soft exoskeleton for immersive drone control},
  author={Nguyen, Chien and Fua, Pascal and others},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2018}
}

@article{realsense_mediapipe,
  title={Real-time pose estimation using Intel RealSense and MediaPipe for human-drone interaction},
  author={Mediapipe Dev Team},
  year={2020}
}

@article{cai_human_drone,
  title={Human-drone interaction based on posture recognition with monocular vision},
  author={Cai, L. and et al.},
  journal={Journal of Intelligent \& Robotic Systems},
  year={2019}
}

@article{leap_motion,
  title={Gesture-based drone control with Leap Motion and Arduino},
  author={Tayebi, Amine},
  journal={International Journal of Advanced Research in Computer Science},
  year={2020}
}

@article{kinect_drone_control,
  title={Drone control using Kinect-based posture detection},
  author={Lee, Sang and others},
  journal={Journal of Intelligent \& Robotic Systems},
  year={2018}
}
@inproceedings{modquad,
	address = {Brisbane, QLD},
	title = {{ModQuad}: {The} {Flying} {Modular} {Structure} that {Self}-{Assembles} in {Midair}},
	isbn = {978-1-5386-3081-5},
	shorttitle = {{ModQuad}},
	url = {https://ieeexplore.ieee.org/document/8461014/},
	doi = {10.1109/ICRA.2018.8461014},
	abstract = {We introduce ModQuad, a novel ﬂying modular robotic structure that is able to self-assemble in midair and cooperatively ﬂy. The structure is composed by agile ﬂying modules that can easily move in a three dimensional environment. The module is based on a quadrotor platform within a cuboid frame which allows it to attach to other modules by matching vertical faces. Using this mechanism, a ModQuad swarm is able to rapidly assemble ﬂying structures in midair using the robot bodies as building units. In this paper, we focus on two important tasks for modular ﬂying structures. First, we propose a decentralized modular attitude controller to allow a team of physically connected modules to ﬂy cooperatively. Second, we develop a docking method that drives pairs of structures to be attached in midair. Our method precisely aligns, and corrects motion errors during the docking process. In our experiments, we tested and analyzed the performance of the cooperative ﬂying method for multiple conﬁgurations. We also tested the docking method with successful results.},
	language = {en},
	urldate = {2024-10-10},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Saldana, David and Gabrich, Bruno and Li, Guanrui and Yim, Mark and Kumar, Vijay},
	month = may,
	year = {2018},
	pages = {691--698},
	file = {Saldana et al. - 2018 - ModQuad The Flying Modular Structure that Self-As.pdf:/home/nicos/Zotero/storage/QNYC56IM/Saldana et al. - 2018 - ModQuad The Flying Modular Structure that Self-As.pdf:application/pdf},
}

@article{reynolds1987boids,
  title={Flocks, Herds, and Schools: A Distributed Behavioral Model},
  author={Reynolds, Craig W.},
  journal={Computer Graphics},
  volume={21},
  number={4},
  pages={25--34},
  year={1987},
  publisher={ACM}
}

@misc{mediapipe2020,
  title={MediaPipe: A Framework for Building Perception Pipelines},
  author={Google Research},
  howpublished={\url{https://google.github.io/mediapipe/}},
  year={2020},
  note={Accessed: 2024-10-10}
}

@misc{noauthor_codevia-iocodeviacenturionnetapi_nodate,
	title = {codevia-io/{Codevia}.{Centurion}.{Net}.{API}},
	url = {https://github.com/codevia-io/Codevia.Centurion.Net.API},
	urldate = {2023-09-08},
	keywords = {code},
	file = {codevia-io/Codevia.Centurion.Net.API:/home/nicos/Zotero/storage/WU42SIJQ/Codevia.Centurion.Net.html:text/html},
}

@misc{noauthor_dvic_nodate,
	title = {{DVIC} - {De} {Vinci} {Innovation} {Center}},
	url = {https://dvic.devinci.fr/tutorial/lighthouse-positioning},
	urldate = {2023-09-07},
	keywords = {site},
	file = {DVIC - De Vinci Innovation Center:/home/nicos/Zotero/storage/3D6GPNDI/lighthouse-positioning.html:text/html},
}

@misc{karaman_sampling-based_2011,
	title = {Sampling-based {Algorithms} for {Optimal} {Motion} {Planning}},
	url = {http://arxiv.org/abs/1105.1186},
	abstract = {During the last decade, sampling-based path planning algorithms, such as Probabilistic RoadMaps (PRM) and Rapidly-exploring Random Trees (RRT), have been shown to work well in practice and possess theoretical guarantees such as probabilistic completeness. However, little effort has been devoted to the formal analysis of the quality of the solution returned by such algorithms, e.g., as a function of the number of samples. The purpose of this paper is to fill this gap, by rigorously analyzing the asymptotic behavior of the cost of the solution returned by stochastic sampling-based algorithms as the number of samples increases. A number of negative results are provided, characterizing existing algorithms, e.g., showing that, under mild technical conditions, the cost of the solution returned by broadly used sampling-based algorithms converges almost surely to a non-optimal value. The main contribution of the paper is the introduction of new algorithms, namely, PRM* and RRT*, which are provably asymptotically optimal, i.e., such that the cost of the returned solution converges almost surely to the optimum. Moreover, it is shown that the computational complexity of the new algorithms is within a constant factor of that of their probabilistically complete (but not asymptotically optimal) counterparts. The analysis in this paper hinges on novel connections between stochastic sampling-based path planning algorithms and the theory of random geometric graphs.},
	urldate = {2023-09-07},
	publisher = {arXiv},
	author = {Karaman, Sertac and Frazzoli, Emilio},
	month = may,
	year = {2011},
	note = {arXiv:1105.1186 [cs]},
	keywords = {Computer Science - Robotics, pdf},
	annote = {1
},
	annote = {Comment: 76 pages, 26 figures, to appear in International Journal of Robotics Research},
	file = {arXiv.org Snapshot:/home/nicos/Zotero/storage/VSTD5TYJ/1105.html:text/html;Full Text PDF:/home/nicos/Zotero/storage/MV2ZTPTU/Karaman and Frazzoli - 2011 - Sampling-based Algorithms for Optimal Motion Plann.pdf:application/pdf},
}

@book{adiyatov_rapidly-exploring_2013,
	title = {Rapidly-exploring random tree based memory efficient motion planning},
	isbn = {978-1-4673-5557-5},
	abstract = {This paper presents a modified version of the RRT* motion planning algorithm, which limits the memory required for storing the tree. We run the RRT* algorithm until the tree has grown to a predefined number of nodes and afterwards we remove a weak node whenever a high performance node is added. A simple two-dimensional navigation problem is used to show the operation of the algorithm. The algorithm was also applied to a high-dimensional redundant robot manipulation problem to show the efficacy. The results show that our algorithm outperforms RRT and comes close to RRT* with respect to the optimality of returned path, while needing much less number of nodes stored in the tree.},
	author = {Adiyatov, Olzhas and Varol, Atakan},
	month = aug,
	year = {2013},
	doi = {10.1109/ICMA.2013.6617944},
	note = {Pages: 359},
	keywords = {pdf},
	annote = {2
},
	file = {Full Text PDF:/home/nicos/Zotero/storage/KBPNWXQI/Adiyatov and Varol - 2013 - Rapidly-exploring random tree based memory efficie.pdf:application/pdf},
}

@misc{matlab_plan_2022,
	title = {Plan {3D} {Paths} for {Drones} {\textbar} {Motion} {Planning} with the {RRT} {Algorithm}, {Part} 4},
	url = {https://www.youtube.com/watch?v=aMhFCBlK-NM},
	abstract = {Are you working with autonomous drone applications such as package delivery or advanced air mobility? Learn how to plan and execute unmanned aerial vehicle (UAV) flights using a guidance model for a fixed-wing aircraft. A fixed-wing UAV is nonholonomic in nature and must obey aerodynamic constraints like maximum roll angle, flight path angle, and airspeed when moving between waypoints.

Watch a demonstration of motion planning of a fixed-wing UAV using the rapidly exploring random tree (RRT) algorithm that is given a start and goal pose on a 3D map. You will learn how to use UAV Toolbox with MATLAB® to generate 3D Dubins motion primitives. You will also learn how to use a customizable path-planning template with Navigation Toolbox™ to define a custom state space and state validator for sampling-based path planning.

Steps include:
- Setting up a 3D map
- Providing the start pose and goal pose
- Planning a path with RRT using 3D Dubins motion primitives
- Smoothing the planned path
- Simulating the UAV flight following the planned path

Watch the full video series:    • Motion Planning Using RRT Algorithm  

Learn More:
- Read ebook: Motion Planning with MATLAB: https://bit.ly/3O04mDe
- See example: Motion Planning with RRT for Fixed-Wing UAV: https://bit.ly/3yyvfbV
- See example: Generate Random 3-D Occupancy Map for UAV Motion Planning: https://bit.ly/3c0Vu2V
- Read documentation: uavDubinsConnection: https://bit.ly/3uK5ggn

Chapters: 
0:37 - Motion Planning Workflow With RRT Algorithm
1:12 - UAV Toolbox Overview
2:05 - Motion Planning with RRT for Fixed-Wing UAV Example
2:52 - Load Map
4:15 - RRT Algorithm Overview
4:52 - 3-D Dubins Motion Primitives
5:39 - Defining the State Space
6:53 - Customizable Path Planning Interface for Sampling-Based Algorithms
8:21 - Defining the State Validator
9:12 - Setup and Execute the RRT Planner
10:38 - Simulate and Visualize the UAV
--------------------------------------------------------------------------------------------------------
Get a free product trial: https://goo.gl/ZHFb5u
Learn more about MATLAB: https://goo.gl/8QV7ZZ
Learn more about Simulink: https://goo.gl/nqnbLe
See what's new in MATLAB and Simulink: https://goo.gl/pgGtod

© 2022 The MathWorks, Inc. MATLAB and Simulink are registered trademarks of The MathWorks, Inc. 
See www.mathworks.com/trademarks for a list of additional trademarks. Other product or brand names may be trademarks or registered trademarks of their respective holders.},
	urldate = {2023-09-07},
	author = {{MATLAB}},
	month = aug,
	year = {2022},
	keywords = {video},
}

@misc{matlab_path_2020,
	title = {Path {Planning} with {A}* and {RRT} {\textbar} {Autonomous} {Navigation}, {Part} 4},
	url = {https://www.youtube.com/watch?v=QR3U1dgc5RE},
	abstract = {See the other videos in this series:    • Autonomous Navigation  

This video explores some of the ways that we can use a map like a binary occupancy grid for motion and path planning. We briefly cover what motion planning means and how we can use a graph to solve this planning problem. We then walk through two popular approaches for creating that graph: search-based algorithms like A* and sampling-based algorithms like RRT and RRT*.

Additional Resources: 
- Planning Mobile-Robot Paths Using RRT MATLAB: https://bit.ly/38PsPZb
- Create an RRT planner: https://bit.ly/2Zoyjac
- Download ebook: Sensor Fusion and Tracking for Autonomous Systems: An Overview: https://bit.ly/32iVFzX
- Download white paper: Sensor Fusion and Tracking for Autonomous Systems: https://bit.ly/2DwbHvK
- Sampling-Based Algorithms for Optimal Motion Planning, Karaman and Frazzoli: https://arxiv.org/pdf/1105.1186.pdf
-  A* Path Finding by Sebastian Lague video:    • A* Pathfinding (E01: algorithm explan...  
- RRT, RRT* \& Random Trees by Aaron Becker video:    • RRT, RRT* \& Random Trees   
- RRT* FND: Motion Planning in Dynamic Environments video:    • RRT* FND - motion planning in dynamic...    

--------------------------------------------------------------------------------------------------------
Get a free product trial: https://goo.gl/ZHFb5u
Learn more about MATLAB: https://goo.gl/8QV7ZZ
Learn more about Simulink: https://goo.gl/nqnbLe
See what's new in MATLAB and Simulink: https://goo.gl/pgGtod

© 2020 The MathWorks, Inc. MATLAB and Simulink are registered trademarks of The MathWorks, Inc. 
See www.mathworks.com/trademarks for a list of additional trademarks. Other product or brand names may be trademarks or registered trademarks of their respective holders.},
	urldate = {2023-09-07},
	author = {{MATLAB}},
	month = jul,
	year = {2020},
	keywords = {video},
}

@misc{noauthor_effective_nodate,
	title = {Effective {Python}},
	file = {_.pdf:/home/nicos/Zotero/storage/NPPQMS9Y/_.pdf:application/pdf},
}

@misc{noauthor_liteffective-pythonpdf_nodate,
	title = {lit/{Effective}-{Python}.pdf at master · camoverride/lit},
	url = {https://github.com/camoverride/lit/blob/master/Effective-Python.pdf},
	abstract = {Literature for the self-taught AI practitioner! 📚. Contribute to camoverride/lit development by creating an account on GitHub.},
	language = {en},
	urldate = {2023-09-11},
	journal = {GitHub},
	file = {Snapshot:/home/nicos/Zotero/storage/3KTJBPE9/Effective-Python.html:text/html},
}

@article{mnih_playing_nodate,
	title = {Playing {Atari} with {Deep} {Reinforcement} {Learning}},
	abstract = {We present the ﬁrst deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We ﬁnd that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	language = {en},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	file = {Mnih et al. - Playing Atari with Deep Reinforcement Learning.pdf:/home/nicos/Zotero/storage/NMG5IIGD/Mnih et al. - Playing Atari with Deep Reinforcement Learning.pdf:application/pdf},
}

@article{mnih_playing_nodate-1,
	title = {Playing {Atari} with {Deep} {Reinforcement} {Learning}},
	abstract = {We present the ﬁrst deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We ﬁnd that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	language = {en},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	file = {Mnih et al. - Playing Atari with Deep Reinforcement Learning.pdf:/home/nicos/Zotero/storage/KM5BGVHK/Mnih et al. - Playing Atari with Deep Reinforcement Learning.pdf:application/pdf},
}

@misc{alex_thiele_deep_2018,
	title = {Deep {Reinforcement} {Learning} with {Unity} and {Python}},
	url = {https://www.youtube.com/watch?v=GDh9NqJTYKA},
	abstract = {Source code can be found here: https://github.com/apockill/DRLPlaygr...

If you have any questions about the source, please shoot me an email and I'll give you the entire project file. I didn't commit the entire project to github because there were some 3d models that took up some memory, and also some assets I downloaded from the asset store. I also didn't bother to document this too heavily, because it was very much a side project for personal research purposes- so just shoot me any questions you might have.

Original DQN paper: https://www.cs.toronto.edu/{\textasciitilde}vmnih/doc... 

Original Model Free Episodic Control paper: https://arxiv.org/abs/1606.04460

Feel free to contact me at Alex.D.Thiel@gmail.com},
	urldate = {2023-09-11},
	author = {{Alex Thiele}},
	year = {2018},
}

@misc{thiele_github_2023,
	title = {Github {Deep} {Reinforcement} {Learning} {Playground}},
	url = {https://github.com/apockill/DRLPlayground},
	abstract = {A deep reinforcement learning playground with Unity running the game physics, and Python handling the reinforcement learning algorithms.},
	urldate = {2023-09-11},
	author = {Thiele, Alex},
	month = aug,
	year = {2023},
	note = {original-date: 2018-01-10T21:45:11Z},
}

@misc{noauthor_crazyflie_nodate,
	title = {Crazyflie + {Crazyswarm} + {Microservice} implementation - {YouTube}},
	url = {https://www.youtube.com/shorts/cKt1O6I8mTA},
	urldate = {2023-09-15},
	file = {Crazyflie + Crazyswarm + Microservice implementation - YouTube:/home/nicos/Zotero/storage/ALCCPPJ3/cKt1O6I8mTA.html:text/html},
}

@misc{noauthor_overview_nodate,
	title = {Overview — {Crazyswarm} 0.3 documentation},
	url = {https://crazyswarm.readthedocs.io/en/latest/overview.html},
	urldate = {2023-09-14},
	file = {Overview — Crazyswarm 0.3 documentation:/home/nicos/Zotero/storage/NXGVFHSK/overview.html:text/html},
}

@inproceedings{lim_6developing_2016,
	title = {[6]{Developing} a {Safety} {Flight} {Assurance} {Control} ({SFAC}) {System} using a {Quadcopter}},
	url = {http://onlinepresent.org/proceedings/vol140_2016/24.pdf},
	doi = {10.14257/astl.2016.140.24},
	abstract = {Recently, with an increase in the use of quadcopters, a lot of cases of damage have taken place due to safety accident and emergency landing. This study aims to prove stabilization, comparing the result values of simulation applying a Kalman filter in a matrix laboratory with data of experiment applying a Kalman filter in Arduino using attitude control sensors and to develop a Safety Flight Assurance Control system which allows the aircraft to maintain level at a constant height and improves stabilization during landing. It is judged that this study will make a great contribution to studies requiring the stabilization of quadcopters for other purposes in the future.},
	language = {en},
	urldate = {2023-09-14},
	author = {Lim, Hyeon-Woo and Jie, Min-Seok and Choi, Won-Hyuck},
	month = dec,
	year = {2016},
	pages = {124--128},
	file = {Lim et al. - 2016 - Developing a Safety Flight Assurance Control (SFAC.pdf:/home/nicos/Zotero/storage/ZSY6JGEV/Lim et al. - 2016 - Developing a Safety Flight Assurance Control (SFAC.pdf:application/pdf},
}

@misc{technologies_powering_nodate,
	title = {Powering the {World}’s {Digital} {Twins} {\textbar} {Unity}},
	url = {https://unity.com/solutions/digital-twins},
	abstract = {Leverage Unity’s technology for digital transformation with connected, dynamic digital twins that unlock and unleash the full power of data for better decision-making.},
	language = {en},
	urldate = {2023-09-12},
	author = {Technologies, Unity},
	file = {Snapshot:/home/nicos/Zotero/storage/FYULRDYX/digital-twins.html:text/html},
}

@inproceedings{jerald_5developing_2014,
	address = {Minneapolis, MN, USA},
	title = {[5]{Developing} virtual reality applications with {Unity}},
	isbn = {978-1-4799-2871-2},
	url = {https://ieeexplore.ieee.org/document/6802117/},
	doi = {10.1109/VR.2014.6802117},
	language = {en},
	urldate = {2023-09-12},
	booktitle = {2014 {IEEE} {Virtual} {Reality} ({VR})},
	publisher = {IEEE},
	author = {Jerald, Jason and Giokaris, Peter and Woodall, Danny and Hartholt, Arno and Chandak, Anish and Kuntz, Sebastien},
	month = mar,
	year = {2014},
	pages = {1--3},
	file = {Jerald et al. - 2014 - Developing virtual reality applications with Unity.pdf:/home/nicos/Zotero/storage/B7EHUGI7/Jerald et al. - 2014 - Developing virtual reality applications with Unity.pdf:application/pdf},
}

@misc{tang_4real-time_2019,
	title = {[4]{Real}-time {Trajectory} {Generation} for {Quadrotors} using {B}-spline based {Non}-uniform {Kinodynamic} {Search}},
	url = {http://arxiv.org/abs/1904.12348},
	abstract = {In this paper, we propose a time-efﬁcient approach to generate safe, smooth and dynamically feasible trajectories for quadrotors in the obstacle-cluttered environment. By using the uniform B-spline to represent trajectories, we transform the trajectory planning to a graph-search problem of B-spline control points in discretized space. Highly strict convex hull property of B-spline is derived to guarantee the dynamical feasibility of the entire trajectory. A novel non-uniform kinodynamic search strategy is adopted, and the step length is dynamically adjusted during the search process according to the Euclidean signed distance ﬁeld (ESDF), making the trajectory achieve reasonable time-allocation and be away from obstacles. Nonstatic initial and goal states are allowed, therefore it can be used for online local replanning as well as global planning. Extensive simulation and hardware experiments show that our method achieves higher performance compared with the state-of-the-art method.},
	language = {en},
	urldate = {2023-09-12},
	publisher = {arXiv},
	author = {Tang, Lvbang and Wang, Hesheng and Li, Peng and Wang, Yong},
	month = nov,
	year = {2019},
	note = {arXiv:1904.12348 [cs]},
	keywords = {Computer Science - Robotics},
	annote = {Comment: 7 pages,6 figures, conference},
	file = {Tang et al. - 2019 - Real-time Trajectory Generation for Quadrotors usi.pdf:/home/nicos/Zotero/storage/FKEAIQWY/Tang et al. - 2019 - Real-time Trajectory Generation for Quadrotors usi.pdf:application/pdf},
}

@misc{terven_3comprehensive_2023,
	title = {[3]{A} {Comprehensive} {Review} of {YOLO}: {From} {YOLOv1} and {Beyond}},
	shorttitle = {A {Comprehensive} {Review} of {YOLO}},
	url = {http://arxiv.org/abs/2304.00501},
	abstract = {YOLO has become a central real-time object detection system for robotics, driverless cars, and video monitoring applications. We present a comprehensive analysis of YOLO’s evolution, examining the innovations and contributions in each iteration from the original YOLO up to YOLOv8, YOLO-NAS, and YOLO with Transformers. We start by describing the standard metrics and postprocessing; then, we discuss the major changes in network architecture and training tricks for each model. Finally, we summarize the essential lessons from YOLO’s development and provide a perspective on its future, highlighting potential research directions to enhance real-time object detection systems.},
	language = {en},
	urldate = {2023-09-12},
	publisher = {arXiv},
	author = {Terven, Juan and Cordova-Esparza, Diana},
	month = aug,
	year = {2023},
	note = {arXiv:2304.00501 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, I.2.10},
	annote = {Comment: 34 pages, 19 figures, 4 tables, submitted to ACM Computing Surveys. This version adds information about YOLO with transformers},
	file = {Terven and Cordova-Esparza - 2023 - A Comprehensive Review of YOLO From YOLOv1 and Be.pdf:/home/nicos/Zotero/storage/8ZDGP5GG/Terven and Cordova-Esparza - 2023 - A Comprehensive Review of YOLO From YOLOv1 and Be.pdf:application/pdf},
}

@inproceedings{greiff_2performance_2019,
	address = {Ottawa, ON, Canada},
	title = {[2]{Performance} {Bounds} in {Positioning} with the {VIVE} {Lighthouse} {System}},
	isbn = {978-0-9964527-8-6},
	url = {https://ieeexplore.ieee.org/document/9011242/},
	doi = {10.23919/FUSION43075.2019.9011242},
	abstract = {The VIVE lighthouse system is evaluated for indoor positioning of micro unmanned aerial vehicles (MUAVs). A detailed mathematical analysis is provided, including a CramerRao bound derivation and performance analysis of the MUAV state estimate. The lighthouse measurements are fused with inertial measurements in a multiplicative extended Kalman ﬁlter (MEKF). We consider two implementations, one with and the other without nonlinear LS pre-ﬁltering, and demonstrate both in a real-time implementation. The results indicate that subcentimeter accuracy in the MUAV positioning, rivalling the best positioning systems on the market at a comparatively low price.},
	language = {en},
	urldate = {2023-09-12},
	booktitle = {2019 22th {International} {Conference} on {Information} {Fusion} ({FUSION})},
	publisher = {IEEE},
	author = {Greiff, Marcus and Robertsson, Anders and Berntorp, Karl},
	month = jul,
	year = {2019},
	pages = {1--8},
	file = {Greiff et al. - 2019 - Performance Bounds in Positioning with the VIVE Li.pdf:/home/nicos/Zotero/storage/4R8EAVPL/Greiff et al. - 2019 - Performance Bounds in Positioning with the VIVE Li.pdf:application/pdf},
}

@inproceedings{giernacki_1crazyflie_2017,
	address = {Miedzyzdroje, Poland},
	title = {[1]{Crazyflie} 2.0 quadrotor as a platform for research and education in robotics and control engineering},
	isbn = {978-1-5386-2402-9},
	url = {http://ieeexplore.ieee.org/document/8046794/},
	doi = {10.1109/MMAR.2017.8046794},
	abstract = {In this paper a Crazyflie 2.0 nano quadrotor helicopter (quadcopter) as an open source experimental platform for research and education in robotics and control engineering has been presented. This low cost, easily expandable and upgradeable flying robot is here characterized in terms of hardware and software. Three aspects, which demonstrate the potential of broad use of this unmanned aerial vehicle (UAV) by researchers and students, are discussed in the paper. The first one is an acquisition of measurement data from test flights by the proposed, freely available “black-box” software. The second is the use of a new, advanced 4FLY Simulator in order to utilize the MATLAB®/Simulink environment to easily implement a mathematical model of Crazyflie 2.0 dynamics, as well as for a synthesis of various types of controllers with support of OpenGL cross-language in the visualization of simulations results. The 4FLY Simulator allows to test autonomous flights (and landings) with obstacles avoidance and to conduct learning and teaching the basics of Crazyflie 2.0 piloting. In the third aspect the authors outlined promising, preliminary results obtained in control of flying robot by pointing device (positioner) and with the support of a vision system, which basis only on a single Kinect sensor.},
	language = {en},
	urldate = {2023-09-12},
	booktitle = {2017 22nd {International} {Conference} on {Methods} and {Models} in {Automation} and {Robotics} ({MMAR})},
	publisher = {IEEE},
	author = {Giernacki, Wojciech and Skwierczynski, Mateusz and Witwicki, Wojciech and Wronski, Pawel and Kozierski, Piotr},
	month = aug,
	year = {2017},
	pages = {37--42},
	file = {Giernacki et al. - 2017 - Crazyflie 2.0 quadrotor as a platform for research.pdf:/home/nicos/Zotero/storage/X3TWJYIY/Giernacki et al. - 2017 - Crazyflie 2.0 quadrotor as a platform for research.pdf:application/pdf},
}

@article{wawrla_applications_nodate,
	title = {Applications of drones in warehouse operations},
	language = {en},
	author = {Wawrla, Lukas and Maghazei, Omid and Netland, Dr Torbjørn},
	file = {Wawrla et al. - Applications of drones in warehouse operations.pdf:/home/nicos/Zotero/storage/FY4AZRJ2/Wawrla et al. - Applications of drones in warehouse operations.pdf:application/pdf},
}
